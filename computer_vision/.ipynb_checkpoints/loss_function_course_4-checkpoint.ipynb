{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022)\n",
      "tensor(0.0111)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5], requires_grad=True)\n",
    "y = torch.tensor([0.14, 0.18, 0.33, 0.49, 0.51])\n",
    "\n",
    "loss = torch.nn.MSELoss(reduction=\"mean\")\n",
    "mse = loss(x, y)\n",
    "print(mse.detach())\n",
    "\n",
    "loss = torch.nn.MSELoss(reduction=\"sum\")\n",
    "mse = loss(x, y)\n",
    "print(mse.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0022)\n",
      "tensor(0.0111)\n"
     ]
    }
   ],
   "source": [
    "sqaure_err = torch.square(x-y)\n",
    "\n",
    "mse = torch.mean(sqaure_err)\n",
    "print(mse.detach())\n",
    "\n",
    "mse = torch.sum(sqaure_err)\n",
    "print(mse.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0380)\n",
      "tensor(0.1900)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.L1Loss(reduction=\"mean\")\n",
    "mae = loss(x, y)\n",
    "print(mae.detach())\n",
    "\n",
    "loss = torch.nn.L1Loss(reduction=\"sum\")\n",
    "mae = loss(x, y)\n",
    "print(mae.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0380)\n",
      "tensor(0.1900)\n"
     ]
    }
   ],
   "source": [
    "l1_err = ...\n",
    "\n",
    "mae = torch.mean(l1_err)\n",
    "print(mae.detach())\n",
    "\n",
    "mae = torch.sum(l1_err)\n",
    "print(mae.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuberLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0011)\n",
      "tensor(0.0055)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.HuberLoss(reduction='mean', delta=1.0)\n",
    "huber = loss(x, y)\n",
    "print(huber.detach())\n",
    "\n",
    "loss = torch.nn.HuberLoss(reduction='sum', delta=1.0)\n",
    "huber = loss(x, y)\n",
    "print(huber.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0011)\n",
      "tensor(0.0055)\n"
     ]
    }
   ],
   "source": [
    "def my_huber(x, y, delta=1, reduction=\"mean\"):\n",
    "    huber_l2 = ...\n",
    "    huber_l1 = ...\n",
    "    condition = ...\n",
    "\n",
    "    t = torch.where(condition, huber_l1, huber_l2)\n",
    "    \n",
    "    if reduction == \"mean\":\n",
    "        return torch.mean(t)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(t)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid arg: {reduction}, only support mean, sum\")\n",
    "\n",
    "huber = my_huber(x, y, reduction=\"mean\")\n",
    "print(huber.detach())\n",
    "\n",
    "huber = my_huber(x, y, reduction=\"sum\")\n",
    "print(huber.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3299)\n",
      "tensor(0.6599)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [[-1, 2.6, 0.1, -0.04, 0.36],\n",
    "    [-0.065, 0, 1.8, 0.1, -10.05]], requires_grad=True\n",
    ")\n",
    "y = torch.tensor([1, 2])\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss(weight=None, ignore_index=-100, reduction='mean')\n",
    "ce = loss(x, y)\n",
    "print(ce.detach())\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "ce = loss(x, y)\n",
    "print(ce.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3299)\n",
      "tensor(0.6599)\n"
     ]
    }
   ],
   "source": [
    "def my_ce(x, y, reduction=\"mean\"):\n",
    "    batch_size, num_cls = x.shape\n",
    "    y = F.one_hot(y, num_classes=num_cls)\n",
    "\n",
    "    ce = ... # hint: torch.log_softmax\n",
    "\n",
    "    if reduction == \"mean\":\n",
    "        return torch.sum(ce) / batch_size\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(ce)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid arg: {reduction}, only support mean, sum\")\n",
    "\n",
    "ce = my_ce(x, y, reduction=\"mean\")\n",
    "print(ce.detach())\n",
    "\n",
    "ce = my_ce(x, y, reduction=\"sum\")\n",
    "print(ce.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0075)\n",
      "tensor(0.3299)\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=[0.1, 0.3], size_average=True):\n",
    "        super(MyFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size, num_cls = x.shape\n",
    "        y = F.one_hot(y, num_classes=num_cls)\n",
    "\n",
    "        softmax_x = torch.softmax(x, dim=1)\n",
    "        softmax_x = torch.sum(softmax_x * y, 1)\n",
    "\n",
    "        at = torch.tensor(self.alpha)\n",
    "        loss = -1*at * (1-softmax_x)**self.gamma * torch.log(softmax_x)\n",
    "        \n",
    "        if self.size_average:\n",
    "            return torch.mean(loss)\n",
    "        else:\n",
    "            return torch.sum(loss)\n",
    "\n",
    "\n",
    "loss = FocalLoss()\n",
    "focal = loss(x, y)\n",
    "print(focal.detach())\n",
    "\n",
    "# Eqauls Cross Entro\n",
    "loss = FocalLoss(gamma=0, alpha=[1, 1])\n",
    "focal = loss(x, y)\n",
    "print(focal.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.2386, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class CenterLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Ref: https://github.com/KaiyangZhou/pytorch-center-loss/blob/master/center_loss.py\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=5, feat_dim=2):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.centers = torch.nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            y: ground truth labels with shape (num_classes).\n",
    "        \"\"\"\n",
    "        batch_size, _ = x.shape\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "\n",
    "        y = y.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = y.eq(classes.expand(batch_size, self.num_classes))\n",
    "        \n",
    "        dist = distmat * mask.float()\n",
    "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n",
    "        \n",
    "        return loss\n",
    "\n",
    "embedding = torch.tensor([[-4.3, 0.26],[3.38, 0.071]], requires_grad=True)\n",
    "y = torch.tensor([1, 2])\n",
    "\n",
    "loss = CenterLoss()\n",
    "center = loss(embedding, y)\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5966)\n"
     ]
    }
   ],
   "source": [
    "triplet_loss = torch.nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "anchor = torch.tensor([[-0.1205, -0.0747,  0.2110,  0.7640, -0.0889, -1.8335,  0.5339,  1.6246, -0.4688,  0.5528, -1.9838,  0.5563,  0.3497,  0.0260, -0.2148,  0.8602]], requires_grad=True)\n",
    "positive = torch.tensor([[-0.7199, -0.2645,  0.2314, -1.0831,  1.6406, -1.6086,  0.2405, -0.3084,-0.0162,  1.1488, -0.9403,  0.2147, -1.5522, -0.0652, -0.0642, -0.5128]], requires_grad=True)\n",
    "negative = torch.tensor([[-0.1581, -1.1795,  1.3480, -0.2423, -0.7676,  0.5932,  2.4350,  1.0902,0.6253, -0.5601, -0.2758,  1.2256, -1.0179,  0.2688, -0.4038,  0.9660]], requires_grad=True)\n",
    "\n",
    "output = triplet_loss(anchor, positive, negative)\n",
    "print(output.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
