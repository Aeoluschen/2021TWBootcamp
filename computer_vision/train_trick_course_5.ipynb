{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook\n",
    "* Stochastic Depth \n",
    "* Warm up \n",
    "* Label Smoothing \n",
    "* No Bias Weight Decay \n",
    "* Teacher-Student Knowledge Distillation \n",
    "* Mixup \n",
    "* Group Normalization \n",
    "* Weight Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def basic_forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if not self.training: #如果沒有在training 階段\n",
    "            out = self.basic_forward(x) #就用一般的forward \n",
    "            return out\n",
    "        else:\n",
    "            if not self.stochastic_depth: #如果不是 stocahstic \n",
    "                out = self.basic_forward(x) #一般forward \n",
    "                return out\n",
    "            else:\n",
    "                actives = torch.bernoulli(self.probability)\n",
    "                if actives == 0:\n",
    "                    print(\"skip\")\n",
    "                    return x\n",
    "                else:\n",
    "                    print(\"run\")\n",
    "                    out = self.basic_forward(x)\n",
    "                    return out\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n",
    "\n",
    "\n",
    "        self.fc2 = nn.Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0\n",
    "        )\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "    \n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes,\n",
    "        planes,\n",
    "        groups,\n",
    "        reduction,\n",
    "        stride=1,\n",
    "        downsample=None,\n",
    "        stochastic_depth=True,\n",
    "        probability=torch.tensor(0.8),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.stochastic_depth = stochastic_depth\n",
    "        self.probability = probability\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes * 2,\n",
    "            planes * 4,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes, kernel_size=1, bias=False)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.se_module = SEModule(\n",
    "            planes,\n",
    "            reduction=reduction,)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEBottleneck(32, 32, 1, 4).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "input_features = torch.randn(4, 32, 32, 32)\n",
    "ouptut = model(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8037999868392944\n"
     ]
    }
   ],
   "source": [
    "# bernoulli\n",
    "value = 0\n",
    "count = 10000\n",
    "for _ in range(count):\n",
    "    value += torch.bernoulli(torch.tensor(0.8))\n",
    "print((value / count).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "## modify from source : https://github.com/Tony-Y/pytorch_warmup#radam-warmup\n",
    "\n",
    "\n",
    "class BaseWarmup:\n",
    "    \"\"\"Base class for all warmup schedules\n",
    "    Arguments:\n",
    "        optimizer (Optimizer): an instance of a subclass of Optimizer\n",
    "        warmup_params (list): warmup paramters\n",
    "        last_step (int): The index of last step. (Default: -1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer: Optimizer, warmup_params, last_step=-1):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_params = warmup_params\n",
    "        self.last_step = last_step\n",
    "        self.step()\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the warmup scheduler as a :class:`dict`.\n",
    "        It contains an entry for every variable in self.__dict__ which\n",
    "        is not the optimizer.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            key: value for key, value in self.__dict__.items() if key != \"optimizer\"\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"Loads the warmup scheduler's state.\n",
    "        Arguments:\n",
    "            state_dict (dict): warmup scheduler state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        self.__dict__.update(state_dict)\n",
    "\n",
    "    def step(self, step=None):\n",
    "        \"\"\"Dampen the learning rates.\n",
    "        Arguments:\n",
    "            step (int): The index of current step. (Default: None)\n",
    "        \"\"\"\n",
    "        if step is None:\n",
    "            step = self.last_step + 1\n",
    "        self.last_step = step\n",
    "\n",
    "        for group, params in zip(self.optimizer.param_groups, self.warmup_params):\n",
    "            omega = self.warmup_factor(step, **params)\n",
    "            group[\"lr\"] *= omega\n",
    "\n",
    "    def warmup_factor(self, step, **params):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class ExponentialWarmup(BaseWarmup):\n",
    "    \"\"\"Exponential warmup schedule.\n",
    "    Arguments:\n",
    "        optimizer (Optimizer): an instance of a subclass of Optimizer\n",
    "        warmup_period (int or list): Effective warmup period\n",
    "        last_step (int): The index of last step. (Default: -1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, warmup_period, last_step=-1):\n",
    "        group_count = len(optimizer.param_groups)\n",
    "        warmup_params = [dict(warmup_period=warmup_period) for _ in range(group_count)]\n",
    "        super().__init__(optimizer, warmup_params, last_step)\n",
    "\n",
    "    def warmup_factor(self, step, warmup_period):\n",
    "        return 1.0 - math.exp(-(step + 1) / warmup_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import optim\n",
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\n",
    "warmup_scheduler = ExponentialWarmup(optimizer, warmup_period=num_steps // 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evan\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "C:\\Users\\Evan\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_ = []\n",
    "for _ in range(num_steps):\n",
    "    lr_scheduler.step(lr_scheduler.last_epoch + 1)\n",
    "    warmup_scheduler.step()\n",
    "    lr_.append(optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VdW1wPHfys1EQhLIQBgSSCBhCIMMYVBQqzigtqIVFeqAiqKvULV2gk6+Wq3V16e1PrRiUSmKgEiVOuFDsE5MYZA5EOYAgZCEzHP2++MebF5Mbm7IcO6wvp9PPt57zj47a+diVvbZ++wtxhiUUkqppgTYHYBSSinPpolCKaWUS5oolFJKuaSJQimllEuaKJRSSrmkiUIppZRLmiiUUkq5pIlCKaWUS5oolFJKuRRodwBtITY21iQlJdkdhlJKeZXNmzefMcbENVfOJxJFUlISGRkZdoehlFJeRUSOuFNObz0ppZRySROFUkopl9xKFCIySUQyRSRLROY0cj5ERJZa5zeISFK9c3Ot45kicnVzdYrIRBHZIiLbROQLEUlpXROVUkq1RrOJQkQcwDzgGiANmCYiaQ2KzQAKjDEpwLPAU9a1acBUYDAwCXhBRBzN1PkicJsxZjiwGPh165qolFKqNdzpUYwBsowxB40xVcASYHKDMpOBhdbr5cBEERHr+BJjTKUx5hCQZdXnqk4DRFqvo4AT59c0pZRSbcGdWU+9gGP13mcDY5sqY4ypEZFCIMY6vr7Btb2s103VeS/wgYiUA0XAuMaCEpGZwEyA3r17u9EMpZRS58OdHoU0cqzhtnhNlWnpcYAfA9caYxKAV4FnGgvKGDPfGJNujEmPi2t2GrBSSqnz5E6PIhtIrPc+gW/fDjpXJltEAnHeMspv5tpvHReROOACY8wG6/hS4CM3YlTnobyqlkNnSjl0ppT80kqKK2uoqqmjU5CDsJBAukeG0js6jD4xYYQGOewOVyllE3cSxSYgVUSSgeM4B6d/0KDMSmA6sA6YAqwxxhgRWQksFpFngJ5AKrARZ4+isToLgCgR6W+M2QdcCexpZRuVxRjDjuOFfLAjh3UH89h5vJDauub3THcECIN6RDAisSuX9I9jQkosnYI1cSjlL5pNFNaYw2xgFeAAXjHG7BKRx4AMY8xKYAGwSESycPYkplrX7hKRZcBuoAaYZYypBWisTuv4fcDbIlKHM3Hc06Yt9kMllTUs3XSM19cf4dCZUgIDhOGJXXjg0r6k9YgiKTaMbhGhRIQGEuQIoKK6ltLKGk4WVnA0v4y9OUVsO3aWFVuyWbT+CCGBAVycGstNIxOYOCie4EB9HEcpXybGNP8XpadLT083uoTHt1VU17Lgi0O89K8DFFXUkN6nKzenJzBpcA+iwoJaXF9VTR2bDufzv7tP8dHOHHKKKogJD2ZKegL3jE8mPjK0HVqhlGovIrLZGJPebDlNFL7pkz2n+O27uzh+tpwrBsUz67J+jOjdtc3qr60zfLY/l6Ubj/Hx7hwCAwL4/she3H9pP5Jjw9vs+yil2o+7icInFgVU/1ZSWcPv/7mbpRnHGNg9gsX3jeWifrFt/n0cAcJlA7px2YBuHM0r4+XPD7Is4xhvbc5m6uhEHroilW4R2sNQyhdoj8KHHMgt4b6FGRzOK+WBS/vx8BX9O3T8ILe4knlrs3h9/RGCAwOYeUlfHri0n86YUspD6a0nP/OvfbnMXryFYEcA824bybi+MbbFcvhMKU+v2ssHO3JIignj8RuGMiG17Xs1SqnWcTdR6HQVH/DPr08w47VNJHQN493Z421NEgBJseG8cNsoXp/hfNj+9gUbeGjJVvJLq2yNSyl1fjRReLllGcd4cMlWRvbpyrL7x5HQNczukL4xITWWjx6+hAcnpvLBjpNc/efPWJt52u6wlFItpInCi/3z6xP84u3tTEiJZeHdY4gIbfmU1/YWGuTgkSv78+6sCUSHBXP3q5v4zTs7Ka+qtTs0pZSbNFF4qc/35/LIsm2M7hPNy3eme/yT0mk9I3l39njunZDMovVH+O7zn7PvVLHdYSml3KCJwgtl5hTzwKLN9IvrzMvT071mVlFokINffzeNN+4dS2F5DZP/50ve3Xbc7rCUUs3QROFlCsuqmbkog7CQQBbeM4aoTp53u6k541Ni+eDBCQzpFclDS7bx6Ls7qaqpszsspVQTNFF4kdo6w0NLt3LibDl/vX2kVy+Z0S0ylMX3jeO+i5NZuO4It85fR25xpd1hKaUaoYnCi7z02QE+zczl0e8NZlSfaLvDabUgRwC/ui6NF24byd6Txdww70v25hTZHZZSqgFNFF5ie/ZZnvl4H9cN7cFtY31rR79rh/bgrQcupKaujpte+Io1e0/ZHZJSqh5NFF6grKqGh5dsI7ZzCE/cOATnduS+ZUivKN6dNYHkuHDuXZjBK18cwhdWDVDKF2ii8AL//fE+Dp4p5ZlbLqBLWLDd4bSb7lGhLLv/Qq5Mi+ex93bzhw/2UOfGxkpKqfalicLD7cgu5NUvD3Hb2N5clOL76yWFBQfy4m2jmH5hH17+/BA/W76d6lqdEaWUndxKFCIySUQyRSRLROY0cj5ERJZa5zeISFK9c3Ot45kicnVzdYrI5yKyzfo6ISLvtK6J3qumto45K7YT0zmEn08aaHc4HSYgQPjP6wfzyJX9eXtLNg8s2qxPcitlo2YThYg4gHnANUAaME1E0hoUmwEUGGNSgGeBp6xr03BuizoYmAS8ICIOV3UaYy42xgw3xgzHuQf3itY30zstXHeEXSeK+N31g73yeYnWEBEenJjK4zcMYU3mae5YsIHCsmq7w1LKL7nToxgDZBljDhpjqoAlwOQGZSYDC63Xy4GJ4hxxnQwsMcZUGmMOAVlWfc3WKSIRwOWAX/YoCkqreG71Pi5OjeWaId3tDsc2t4/rw7wfjGR7diG3zl9HXok+a6FUR3MnUfQCjtV7n20da7SMMaYGKARiXFzrTp03Ap8YYxqdWC8iM0UkQ0QycnNz3WiGd/nLmv2UVNbw6+vSfHKWU0tcO7QHC+5K59CZUqa9vF4fzFOqg7mTKBr7LdVwKkpTZVp6vL5pwJtNBWWMmW+MSTfGpMfFxTVVzCsdzC1h0boj3Dq6NwO6R9gdjke4ODWOV+8ezbH8cqbOX8epogq7Q1LKb7iTKLKBxHrvE4ATTZURkUAgCsh3ca3LOkUkBuftqffdaYSv+eOHewkJDOCRK/vbHYpHuahfLAvvGUNOYQVT56/nZGG53SEp5RfcSRSbgFQRSRaRYJyD0ysblFkJTLdeTwHWGOfTUiuBqdasqGQgFdjoRp03A+8ZY/zuz8bt2Wf5ePcpHri0H3ERIXaH43HGJEfz9xljOFNcya0vrSe7oMzukJTyec0mCmvMYTawCtgDLDPG7BKRx0TkeqvYAiBGRLKAR4A51rW7gGXAbuAjYJYxprapOut926m4uO3ky55bvZ8uYUHcNT7J7lA81qg+0bx+71jOllUx7eX15BT63d8TSnUo8YVlEtLT001GRobdYbTajuxCvvc/X/DTq/oz+/JUu8PxeNuOneX2v22gW2QIS2deqD0wpVpIRDYbY9KbK6dPZnuQ5z7ZR1SnIKZflGR3KF5heGIXXr17NCfPVnDHgg0UlFbZHZJSPkkThYfYebyQ1XtOc9/FyR6597WnGp0Uzd+mp3PwTCl3vLKBwnJ9KE+ptqaJwkPM/+wgESGB2ps4D+NTYnnp9lFk5hRz96sbKa2ssTskpXyKJgoPcOJsOe/vOMnUMYnamzhPlw3sxvPTRvB1diH3LsygolrXhlKqrWii8AALvzoMoL2JVpo0pAd/unkY6w7m8fCSbdTqEuVKtQlNFDYrqaxh8cajXDOkOwldw+wOx+vdOCKB3343jY925fDrd3bq5kdKtYFAuwPwd29lHKO4ooZ7L+5rdyg+454JyeSVVjJv7QFiOwfzk6sG2B2SUl5NE4WN6uoMr311mPQ+XRme2MXucHzKT68aQF5JFc+vySI6PJi7xyfbHZJSXksThY3WHczjSF6ZrunUDkSEx28YQkFZFb/7526iw4OZPLzhAsVKKXfoGIWNFm84StewIK4e7L/7TbSnQEcAz00dwdjkaH6y7Gv+tc/3lqNXqiNoorBJbnElq3blcNPIBEKDHHaH47NCgxy8PD2d/vER/PD1zew6UWh3SEp5HU0UNlm+OZuaOsPUMb3tDsXnRYYG8erdo4nqFMQ9r23ixFldnlypltBEYYO6OsOSTUcZkxxNSrfOdofjF+IjQ3n17jGUVdZy96ubKKrQpT6UcpcmChusP+QcxP6B9iY61IDuEfz1jlEcyC3hh69voaqmzu6QlPIKmihs8I8tx+kcEsikITqI3dHGp8Tyx5uG8UXWGeau2KEP5CnlBp0e28Eqqmv5cGcO1wzproPYNpkyKoHjBeU8u3ofidGdePgKnZ6slCtu9ShEZJKIZIpIlojMaeR8iIgstc5vEJGkeufmWsczReTq5uoUpydEZJ+I7BGRB1vXRM+yes8pSipruHGEzum304MTU5gyKoE/r97PWxnH7A5HKY/WbI9CRBzAPOBKIBvYJCIrjTG76xWbARQYY1JEZCrwFHCriKTh3NZ0MNATWC0i5/58a6rOu4BEYKAxpk5EurVFQz3FO1uP0z0ylLF9Y+wOxa+JCE9+fyg5hRXMXbGDXl06cVFKrN1hKeWR3OlRjAGyjDEHjTFVwBJgcoMyk4GF1uvlwEQREev4EmNMpTHmEJBl1eeqzv8AHjPG1AEYY06ff/M8S35pFZ9m5jJ5eE8cAWJ3OH4vyBHAC7ePpG9cOA+8vpmDuSV2h6SUR3InUfQC6vfNs61jjZYxxtQAhUCMi2td1dkPZ28kQ0Q+FJFGN48WkZlWmYzcXO944va97SeoqTPcOFJvO3mKyNAgFkwfTaAjgBkLMzhbptupKtWQO4misT99G04VaapMS48DhAAV1obfLwOvNBaUMWa+MSbdGJMeFxfXaOCeZuW2EwzsHsHA7pF2h6LqSYwO46U7RnG8oJwfvrGF6lqdNqtUfe4kimycYwbnJAAnmiojIoFAFJDv4lpXdWYDb1uv/wEMcyNGj3eqqILNRwu4dmgPu0NRjRidFM2T3x/KVwfy+O27u3TarFL1uJMoNgGpIpIsIsE4B6dXNiizEphuvZ4CrDHO/9NWAlOtWVHJQCqwsZk63wEut15fCuw7v6Z5llW7cjAGrtFnJzzWTaMS+I/v9OPNjUd59cvDdoejlMdodtaTMaZGRGYDqwAH8IoxZpeIPAZkGGNWAguARSKShbMnMdW6dpeILAN2AzXALGNMLUBjdVrf8o/AGyLyY6AEuLftmmufD3fkkNKtM6nxEXaHolz42VUDOJhbwuPv7yY5LpzLBvjUpDulzov4Qhc7PT3dZGRk2B1Gk/JKKhn9xGpmXZaiu615gbKqGqa8uI6j+WW8/R8XMaC7Jnflm0RkszUe7JIu4dEBPt59ijqDLtnhJcKCA1lwVzqdgh3MWLiJMyWVdoeklK00UXSAD3fm0CcmjLQeOtvJW/SI6sTf7kwnt7iSBxZtprKm1u6QlLKNJop2VlhWzVdZZ5g0pDvOZxCVt7ggsQt/uvkCMo4U8KjOhFJ+TBcFbGf/2p9LTZ3hqrR4u0NR5+F7F/Rkb04R89YeYHDPSO64MMnukJTqcNqjaGdr9pwiOjyY4Yld7Q5FnaefXDmAiQO78bt/7mbdgTy7w1Gqw2miaEe1dYZP9+XynQFxuraTFwsIEJ6dOpw+MWHMWryFY/lldoekVIfSRNGOth4t4GxZNZcP1Ln43i4yNIiX70ynuraOmYs2U1ZVY3dISnUYTRTtaM3e0wQGCBenesdaVMq1vnGdeX7aCDJzivjZW9t1cFv5DU0U7WjN3tOMToomqlOQ3aGoNvKdAd34xaSBvL/jJC98esDucJTqEJoo2snxs+XszSnW204+aOYlfZk8vCd/+jiT1btP2R2OUu1OE0U7WbPXud/S5YM0UfgaEeGpm4YxuGckDy/dRtbpYrtDUqpdaaJoJ//KzCUxuhN9Y8PtDkW1g9AgB/PvSCc0KID7/r6ZwrJqu0NSqt1oomgH1bV1rD+Yx8Wpcfo0tg/r2aUTL94+iuyCMn60ZCu1dTq4rXyTJop2sD37LCWVNUxIibU7FNXORidF89jkIXy2L5enV+21Oxyl2oUminbw+f4ziMBF/WLsDkV1gGljevODsb156V8HeX/7SbvDUarNaaJoB1/sP8OwXlF0CQu2OxTVQR79Xhoje3fhZ8u/JjNHB7eVb3ErUYjIJBHJFJEsEZnTyPkQEVlqnd8gIkn1zs21jmeKyNXN1Skir4nIIRHZZn0Nb10TO1ZxRTVbj51lQqredvInIYEOXrx9FOEhgdy/KIPCch3cVr6j2UQhIg5gHnANkAZME5G0BsVmAAXGmBTgWeAp69o0nNuiDgYmAS+IiMONOn9mjBlufW1rVQs72IaD+dTWGcbr+ITfiY8M5cXbRpJdUM7DS7ZSp4Pbyke406MYA2QZYw4aY6qAJcDkBmUmAwut18uBieKc7jMZWGKMqTTGHAKyrPrcqdMrfZF1hk5BDkb10dVi/VF6UjSPXj+YtZm5/Hn1PrvDUapNuJMoegHH6r3Pto41WsYYUwMUAjEurm2uzidEZLuIPCsiIW7E6DE+35/LmORoQgIddoeibHL72N7cPCqBv6zJYtWuHLvDUarV3EkUjT0I0LBP3VSZlh4HmAsMBEYD0cAvGg1KZKaIZIhIRm5ubmNFOtzpogoO5JYyPkVnO/kzEeH3NwxhWEIUP1n2NVmnS+wOSalWcSdRZAOJ9d4nACeaKiMigUAUkO/i2ibrNMacNE6VwKs4b1N9izFmvjEm3RiTHhfnGauzbjiUD8DYZE0U/i40yMFfbx9FSGAAMxdlUFyhg9vKe7mTKDYBqSKSLCLBOAenVzYosxKYbr2eAqwxzjWYVwJTrVlRyUAqsNFVnSLSw/qvADcAO1vTwI604VAe4cEOBveMtDsU5QF6dunEvNtGciSvjJ8s+1oHt5XXajZRWGMOs4FVwB5gmTFml4g8JiLXW8UWADEikgU8Asyxrt0FLAN2Ax8Bs4wxtU3VadX1hojsAHYAscDjbdPU9rfhYD6jkqIJdOjjKcppXN8YfnXtID7efYp5a7PsDkep8xLoTiFjzAfABw2O/bbe6wrg5iaufQJ4wp06reOXuxOTp8krqWT/6RJuGNFwnF/5u7vHJ7E9+yzPrN7HkF5RXKZLzysvo3/6tpFNh53jE+P6RtscifI0IsKT3x/GoO6RPLhkK4fPlNodklItoomijaw/mE9oUABDe3WxOxTlgToFO3jpjlE4AoSZizIordQ9t5X30ETRRjYeymdk764EB+qPVDUuMTqM56eNIOt0CT9frntuK++hv9XaQGFZNXtyinRarGrWxalx3+y5/dJnB+0ORym3aKJoA5sO52MMjEnW8QnVvJmX9OW6YT14+qO9fL7fMx4WVcoVTRRtIONIAUEOYURvHZ9QzRMRnr5pGKndIvjRm1s5ll9md0hKuaSJog1sOVJAWs8oQoN0fSflnvCQQF66YxR1dYaZizZTXlVrd0hKNUkTRStV19ax/fhZRmpvQrVQUmw4z00dwd6cIuas0MFt5bk0UbTSnpNFVFTX6bLi6rxcNrAbP7myP+9uO8GCLw7ZHY5SjdJE0UqbjxQAMLK3Jgp1fn74nRSuHhzPkx/u5ausM3aHo9S3aKJopS1Hz9I9MpSeXTrZHYryUgEBwn/fMpzk2HBmLd5CdoEObivPoomilbYcKWBkHx2fUK3TOSSQ+XeMoqbOcL8ObisPo4miFU4VVXD8bLnedlJtom9cZ56bOpzdJ4uYq4PbyoNoomiFLefGJ3QgW7WRywfG8+Mr+vPOthO88uVhu8NRCtBE0SpbjhYQ7AjQjYpUm5p9WQpXpcXzhw/28NUBHdxW9tNE0Qpbjp5lSK9IQgL1QTvVdgIChGdudQ5uz168VQe3le3cShQiMklEMkUkS0TmNHI+RESWWuc3iEhSvXNzreOZInJ1C+p8XkQ8dlf66to6dh4vZISOT6h20Nl6cru6po4HXt9MRbUObiv7NJsoRMQBzAOuAdKAaSKS1qDYDKDAGJMCPAs8ZV2bhnM/7MHAJOAFEXE0V6eIpAMePZVo36liKmvqGJYQZXcoykf1i+vMn6cOZ+fxIn65YocObivbuNOjGANkGWMOGmOqgCXA5AZlJgMLrdfLgYkiItbxJcaYSmPMISDLqq/JOq0k8l/Az1vXtPa1I7sQgGEJHp3PlJebOMg5uL1i63Fe++qw3eEoP+VOougFHKv3Pts61mgZY0wNUAjEuLjWVZ2zgZXGmJPuNcEeX2cXEhEaSFJMmN2hKB/3o8tTuDItnsff38O6A3l2h6P8kDuJQho51rAP3FSZFh0XkZ7AzcDzzQYlMlNEMkQkIze349f033H8LMMSonB2nJRqPwEBwjO3XEBSTBizF2/h+Nlyu0NSfsadRJENJNZ7nwCcaKqMiAQCUUC+i2ubOj4CSAGyROQwECYiWY0FZYyZb4xJN8akx8XFudGMtlNRXUtmTrHedlIdJiI0iPl3plNZU8cDi3RwW3UsdxLFJiBVRJJFJBjn4PTKBmVWAtOt11OANcY58rYSmGrNikoGUoGNTdVpjHnfGNPdGJNkjEkCyqwBco+yN6eY6lrDsF46kK06Tr+4zjx763B2HC/kl//QwW3VcZpNFNaYw2xgFbAHWGaM2SUij4nI9VaxBUCM9df/I8Ac69pdwDJgN/ARMMsYU9tUnW3btPazI/ssAMMStUehOtaVafE8fEUqK7YcZ6EObqsOEuhOIWPMB8AHDY79tt7rCpxjC41d+wTwhDt1NlKmszvxdbSvswuJCQ+mZ1So3aEoP/Tg5ansPF7E79/fw8AekYzrG2N3SMrH6ZPZ52FHdiFDdSBb2cT55PYF9IkJY9YbWzihg9uqnWmiaKGyqhr2n9aBbGWvyNAg5t9hDW7rk9uqnWmiaKFdJ4qoM+hAtrJdSrfOPHPLBWzPLuTX7+zUwW3VbjRRtNCu484nsodoolAe4KrB3XloYirLN2frsuSq3WiiaKHdJ4uICQ8mPjLE7lCUAuChialcPTieJ97fzWf7Ov7hU+X7NFG00O6TRaT1jNSBbOUxnE9uD6d/fASzF2/hYK7HLrqsvJQmihaorq1jX04JaT10oyLlWcJDAnn5znQCHQHc+/cMCsur7Q5J+RBNFC1wILeEqto60nRHO+WBEqPDePG2kRzNK+PBN7dSW6eD26ptaKJogd0nigC0R6E81ti+Mfz+hiH8a18uf/xwj93hKB/h1pPZymn3iSJCAgNIjg23OxSlmjRtTG/2nizi5c8PMaB7JFNGJdgdkvJy2qNogd0nixjYPYJAh/7YlGf7zXfTGJ8Swy9X7GDzkQK7w1FeTn/juckY882MJ6U8XaAjgHk/GEmPLqHcv2izLvOhWkUThZtOFlZwtqxaxyeU1+gSFszf7kynorqWmYsyKK/SZT7U+dFE4aZvBrK1R6G8SGp8BH+ZNpxdJ4r42fKvdZkPdV40Ubhp98kiRGBAd00UyrtcPjCeX0wayHvbTzJvbaMbRirlks56ctPuE0UkxYTTOUR/ZMr73H9JXzJzivnTx/voG9eZa4f2sDsk5UXc6lGIyCQRyRSRLBGZ08j5EBFZap3fICJJ9c7NtY5nisjVzdUpIgtE5GsR2S4iy0XEIzYvyjxVzID4CLvDUOq8iAhPfn8oI3t34cdLt7Ht2Fm7Q1JepNlEISIOYB5wDZAGTBORtAbFZgAF1v7WzwJPWdem4dwPezAwCXhBRBzN1PljY8wFxphhwFGcW6baqqK6lsN5pQzorolCea/QIAcv35lOt8gQ7l2YwXGdCaXc5E6PYgyQZYw5aIypApYAkxuUmQwstF4vByaKc9W8ycASY0ylMeYQkGXV12SdxpgiAOv6ToDto29Zp0swBk0UyuvFdA7hlemjqaypZcZrmyiu0DWhVPPcSRS9gGP13mdbxxotY4ypAQqBGBfXuqxTRF4FcoCBwPNuxNiuMnOKAeivt56UD0iNj+DF20ax/3QJP3pzKzW1dXaHpDycO4misfW0G/6V31SZlh53vjDmbqAnsAe4tdGgRGaKSIaIZOTmtu8a/PtOFRPsCCApJqxdv49SHWVCaiy/nzyETzNzefx9XRNKueZOosgGEuu9TwBONFVGRAKBKCDfxbXN1mmMqQWWAjc1FpQxZr4xJt0Ykx4XF+dGM85f5qli+nXrrEt3KJ/yg7G9ue/iZF776jCvfXnI7nCUB3PnN98mIFVEkkUkGOfg9MoGZVYC063XU4A1xvlkz0pgqjUrKhlIBTY2Vac4pcA3YxTfA/a2romtt/9UCQPiPWLylVJtas41g7gyLZ7H3tvN2r2n7Q5HeahmE4U15jAbWIXzVtAyY8wuEXlMRK63ii0AYkQkC3gEmGNduwtYBuwGPgJmGWNqm6oT5y2phSKyA9gB9AAea7PWnofiimqOny2nvw5kKx/kCBCemzqcQT0imb14C3tOFtkdkvJA4guP9Kenp5uMjIx2qXvzkQJuevErFkxPZ+Kg+Hb5HkrZLaewgsnzvsAhwjuzxtMtMtTukFQHEJHNxpj05srpTfdm7DulM56U7+seFcqC6aM5W17N3a9toqSyxu6QlAfRRNGMzJxiwoId9OrSye5QlGpXQ3pFMe+2kezNKeaHb2yhWqfNKosmimbsO1VManwEAQGNzehVyrdcNqAbT944lM/25TJ3xQ5dbVYBuihgs/adKubygd3sDkOpDnPL6EROFJbz59X76dmlE49c2d/ukJTNNFG4cKakkjMlVTo+ofzOQxNTOXG2nL98sp8eUaFMG9Pb7pCUjTRRuHBuIFvXeFL+RkR44sahnCqq5Nfv7CQ+MoTLB+qsP3+lYxQu7LPWeNLlxZU/CnIE8MJtIxnUI4JZb2xle7YuTe6vNFG4kJVbQkRoIHERIXaHopQtwkMCeeWu0cR0Duae1zZxNK/M7pCUDTRRuHAkNgq0AAATZElEQVQwt5SUbp1xriailH/qFhHKwnvGUFNnmP7qRs6UVNodkupgmihcOJBbQr84XeNJqX5xnVkwPZ2TheVMf2UjRbqPhV/RRNGE4opqThVV0jcu3O5QlPIIo/pE8+Lto8jMKebehRlUVNfaHZLqIJoomnAwtxRAexRK1XPZgG789y0XsOlwPrMX66ZH/kITRRMO5JYAmiiUamjy8F48dv1gVu85xS/e3kFdnT697ev0OYomHMgtITBA6KO72in1LXdcmER+aTXPrt5Hl7Agfn3dIJ304cM0UTThwOlSeseEEaS72inVqAcnplBQVsWCLw4RHR7MrMtS7A5JtRNNFE3QGU9KuSYi/Pa7aRSWV/NfqzKJ6hTE7eP62B2Wagdu/bksIpNEJFNEskRkTiPnQ0RkqXV+g4gk1Ts31zqeKSJXN1eniLxhHd8pIq+ISFDrmthyNbV1HM4r1UShVDMCAoSnpwxj4sBu/ObdnazYkm13SKodNJsoRMQBzAOuAdKAaSKS1qDYDKDAGJMCPAs8ZV2bhnM/7MHAJOAFEXE0U+cbwEBgKNAJuLdVLTwPxwrKqa419NOpsUo1K8gRwLzbRnJRvxh++tbXvLf9hN0hqTbmTo9iDJBljDlojKkClgCTG5SZDCy0Xi8HJopzZGsysMQYU2mMOQRkWfU1Wacx5gNjATYCCa1rYssdtGY89dUehVJuCQ1y8PKd6aT3ieahJdtYtSvH7pBUG3InUfQCjtV7n20da7SMMaYGKARiXFzbbJ3WLac7gI/ciLFN/XtqrPYolHJXWHAgr9w9mmEJUcxevIW1e0/bHZJqI+4kisbmvDWcON1UmZYer+8F4DNjzOeNBiUyU0QyRCQjNze3sSLn7cDpUmI7B9MlLLhN61XK13UOCeS1u8cwoHsE97++mS+zztgdkmoD7iSKbCCx3vsEoOFNyG/KiEggEAXku7jWZZ0i8igQBzzSVFDGmPnGmHRjTHpcXJwbzXDfgdwSve2k1HmK6hTEonvG0jc2nBkLN7HhYJ7dIalWcidRbAJSRSRZRIJxDk6vbFBmJTDdej0FWGONMawEplqzopKBVJzjDk3WKSL3AlcD04wxtqwPoFNjlWqdruHBLJoxll5dOnHPa5vYfCTf7pBUKzSbKKwxh9nAKmAPsMwYs0tEHhOR661iC4AYEcnC2QuYY127C1gG7MY51jDLGFPbVJ1WXX8F4oF1IrJNRH7bRm11S35pFQVl1To+oVQrxUWEsPi+cXSLDOXOBRvZeEiThbcS5x/+3i09Pd1kZGS0SV2bDudz81/X8epdo7lsYLc2qVMpf3a6qIJpL6/nxNkKFtyVzkX9Yu0OSVlEZLMxJr25cro+RQOHzzhXjU2K1R6FUm2hW2QoS2ZeSGK08zbUF/t1gNvbaKJo4EheGY4AIaFrJ7tDUcpnxEWE8OZ940iKCeeehZv4NFOnznoTTRQNHMorJaFrJ10MUKk2FtPZOWaREteZmX/fzCd7TtkdknKT/jZs4EheKUkxettJqfYQHR7M4vvGMqB7BA+8vpmPdp60OyTlBk0U9RhjOHKmjCTdg0KpdtMlLJjX7x3L0F5R/PCNLSzbdKz5i5StNFHUk1daRXFlDX20R6FUu4rqFMTr945lfEosP397Oy9/dtDukJQLmijqOZLnnPGUrDOelGp3YcGB/G16OtcN7cETH+zhv1btxRem6/si3bionsNnygB0+1OlOkhIoIO/TBtBZKdA5q09wNmyah6bPARHgG6r6kk0UdRzOK/UmhqriUKpjuIIEP5w41C6hAXz4qcHKCyv5plbhhMcqDc8PIUminoO55XRq0sn/QeqVAcTEX4xaSBdOgXx5Id7ySup4q93jCKqU4dvcKkaob8R6zmSV6q3nZSy0f2X9uPZWy8g40g+N//1K46fLbc7JIUmim8YYzh0plQHspWy2Y0jElh4zxhOFlZw47wv2Xm80O6Q/J4mCktBWTXFFTo1VilPcFG/WN7+j4sIDBBufWmdLvlhM00UlkNnzk2N1VtPSnmC/vER/GPWePrEhDNjYQaLNxy1OyS/pYnCcu4ZCu1RKOU54iNDWfbAhVycGssv/7GDR9/dSXWtLfuZ+TVNFJbDeWUECCTq1FilPErnkEAWTB/NfRcns3DdEaa/spGC0iq7w/IrbiUKEZkkIpkikiUicxo5HyIiS63zG0Qkqd65udbxTBG5urk6RWS2dcyISIftcHL4TCm9uurUWKU8kSNA+NV1afzp5gvIOFzADS98yb5TxXaH5Tea/a0oIg5gHnANkAZME5G0BsVmAAXGmBTgWeAp69o0nPthDwYmAS+IiKOZOr8ErgCOtLJtLaKrxirl+aaMSmDJ/eMoq6rl+y98xerdulR5R3Dnz+cxQJYx5qAxpgpYAkxuUGYysNB6vRyYKCJiHV9ijKk0xhwCsqz6mqzTGLPVGHO4le1qscN5ZfoMhVJeYGTvrqycPZ7k2HDuW5TBM/+7j9o6XSOqPbmTKHoB9dcBzraONVrGGFMDFAIxLq51p84OU1hWTWF5NX2itUehlDfoEdWJtx64kJtGJvCXT/Yz/ZWNnCmptDssn+VOomhsda6G6bupMi097jYRmSkiGSKSkZub25JLv+VYgXMxwMRo3f5UKW8RGuTgTzdfwNM3DWPT4Xyu+8vnbDqcb3dYPsmdRJENJNZ7nwCcaKqMiAQCUUC+i2vdqdMlY8x8Y0y6MSY9Li6uJZd+y7F8Z6LQxQCV8j63jE5kxQ8vIjTIwdT563n5s4O6XHkbcydRbAJSRSRZRIJxDk6vbFBmJTDdej0FWGOcn9RKYKo1KyoZSAU2ullnh/l3j0IThVLeaHDPKP75owlcOSieJz7Ywz2vbSK3WG9FtZVmE4U15jAbWAXsAZYZY3aJyGMicr1VbAEQIyJZwCPAHOvaXcAyYDfwETDLGFPbVJ0AIvKgiGTj7GVsF5G/tV1zG3csv5zI0EBdqVIpLxYZGsSLt4/kd9cP5qsDeUz682es2auzotqC+EIXLT093WRkZJz39Xe96hwIe+9HF7dhVEopu+w7VcyDb25lb04xd4zrwy+vHUSnYIfdYXkcEdlsjElvrpw+XQYczS/TJ7KV8iH94yN4d/Z47rs4mUXrj/C9//mCbcfO2h2W1/L7RFFXZ8guKNfxCaV8TEigg19dl8brM8ZSWlnD91/4kj98sIfyqlq7Q/M6fp8ocksqqaqpI7GrTo1VyhdNSI1l1Y8v4dbRvZn/2UGuee4zNhzMszssr+L3ieKbqbHao1DKZ0WGBvHk94ey+N6x1BrDrfPX85t3dlJYXm13aF5BE8W5qbE6RqGUz7soJZZVD1/C3eOTeH3DESb+96cs35xNnS4B4pLfJ4qjec49eRP01pNSfiEsOJBHvzeYf86eQGJ0GD9962tufmkdu07olqtN8ftEcaygjPjIEEKDdOqcUv5kSK8o3n7gIp6eMozDZ0r53vNf8Jt3duqaUY3QRKFTY5XyWwEBwi3piaz56Xe488IkFm88yqVPr+W51fsprayxOzyP4feJQqfGKqWiOgXxn9cP5uMfX8Il/eN4dvU+Lv2vT1m0/ohuvYqfJ4qqmjpOFpbr1FilFAD94jrz4u2jWPHDi+gbG85v3tnJZX/6lDc2HKGyxn+fv/DrRHHibDl1RhcDVEr9fyN7d2Xp/eN49a7RxHYO4Vf/2MklT6/llS8O+eUDe4F2B2AnXTVWKdUUEeGygd34zoA4vszK4/k1+3nsvd3MW5vFD8b25vZxfYiPDLU7zA7h34ki3zk1VhOFUqopIsKE1FgmpMay8VA+L/3rAP+zNosXPz3AtUN7cPf4JIYndsG5+7Nv8u9EUVBGkEPo7id/FSilWmdMcjRjkqM5klfK39cdYdmmY6z8+gQDu0cwZVQCN4zoRWznELvDbHN+PUZxLL+Mnl064Qjw3b8ElFJtr09MOL/5bhrrfjmRx28YQkiQg8ff38O4P3zCvQszeG/7CZ+aXuvXPYqUbp3pFqG9CaXU+ekcEsjt4/pw+7g+7D9VzPLN2azYepzVe04RHBjAJalxTBrSnSsGdaNLWLDd4Z43tzYuEpFJwHOAA/ibMeaPDc6HAH8HRgF5wK3GmMPWubnADKAWeNAYs8pVndaWqUuAaGALcIcxpspVfK3duEgppdpKbZ1h0+F8PtqZw6pdOZwsrCBAYGivKManxDIhJZaRfbp6xGoQ7m5c1GyiEBEHsA+4EsjGud/1NGPM7nplfggMM8Y8ICJTgRuNMbeKSBrwJjAG6AmsBvpblzVap4gsA1YYY5aIyF+Br40xL7qKUROFUsoTGWP4OruQtXtP82XWGbYeO0ttnSE4MIDBPSO5IKELwxO7MCwhij4x4R1+G7wtE8WFwH8aY6623s8FMMY8Wa/MKqvMOhEJBHKAOP69d/aT9ctZl32rTuCPQC7Q3RhT0/B7N0UThVLKGxRXVLPxUD7rDuSxPbuQHccLKa92PpcREhhAcmw4/eI60zcunMToMLpFhBAfGUq3iBC6hAW3eSJxN1G4M0bRCzhW7302MLapMtYv+EIgxjq+vsG1vazXjdUZA5w1xtQ0Ul4ppbxaRGgQEwfFM3FQPAA1tXXsP13CjuxC9p8u5mBuKbtOFPLhzpM0tvJ5aFAA4cGBhIU4CHIEECDCK9NH0zumfaf4u5MoGkthDZvQVJmmjjc228pV+W8HJTITmAnQu3fvxooopZRHC3QEMKhHJIN6RP6/45U1tZwuquR0cQWniio5VVRBUXkNZVU1lFbVUFpZS3VtHXXGEBLU/pNX3UkU2UBivfcJwIkmymRbt56igPxmrm3s+Bmgi4gEWr2Kxr4XAMaY+cB8cN56cqMdSinlFUICHSRGh3nMw8DupKJNQKqIJItIMDAVWNmgzEpguvV6CrDGOAc/VgJTRSTEms2UCmxsqk7rmrVWHVh1vnv+zVNKKdVazfYorDGH2cAqnFNZXzHG7BKRx4AMY8xKYAGwSESycPYkplrX7rJmMe0GaoBZxphagMbqtL7lL4AlIvI4sNWqWymllE3ceo7C0+msJ6WUajl3Zz359RIeSimlmqeJQimllEuaKJRSSrmkiUIppZRLmiiUUkq55BOznkQkFzhynpfH4nzQz59om/2Dttk/tKbNfYwxcc0V8olE0RoikuHO9DBfom32D9pm/9ARbdZbT0oppVzSRKGUUsolTRTWwoJ+RtvsH7TN/qHd2+z3YxRKKaVc0x6FUkopl/w6UYjIJBHJFJEsEZljdzxtQUQSRWStiOwRkV0i8pB1PFpE/ldE9lv/7WodFxH5i/Uz2C4iI+1twfkTEYeIbBWR96z3ySKywWrzUmtJe6xl75dabd4gIkl2xn2+RKSLiCwXkb3W532hr3/OIvJj69/1ThF5U0RCfe1zFpFXROS0iOysd6zFn6uITLfK7xeR6Y19L3f5baIQEQcwD7gGSAOmiUiavVG1iRrgJ8aYQcA4YJbVrjnAJ8aYVOAT6z04259qfc0EXuz4kNvMQ8Ceeu+fAp612lwAzLCOzwAKjDEpwLNWOW/0HPCRMWYgcAHOtvvs5ywivYAHgXRjzBCcWxRMxfc+59eASQ2OtehzFZFo4FGcW0yPAR49l1zOizHGL7+AC4FV9d7PBebaHVc7tPNd4EogE+hhHesBZFqvXwKm1Sv/TTlv+sK5G+InwOXAezi31T0DBDb8vHHug3Kh9TrQKid2t6GF7Y0EDjWM25c/Z6AXcAyItj6394CrffFzBpKAnef7uQLTgJfqHf9/5Vr65bc9Cv79j+6cbOuYz7C62iOADUC8MeYkgPXfblYxX/k5/Bn4OVBnvY8Bzhrnlrrw/9v1TZut84VWeW/SF8gFXrVut/1NRMLx4c/ZGHMc+BNwFDiJ83PbjG9/zue09HNt08/bnxOFNHLMZ6aAiUhn4G3gYWNMkauijRzzqp+DiHwXOG2M2Vz/cCNFjRvnvEUgMBJ40RgzAijl37cjGuP1bbZunUwGkoGeQDjOWy8N+dLn3Jym2timbffnRJENJNZ7nwCcsCmWNiUiQTiTxBvGmBXW4VMi0sM63wM4bR33hZ/DeOB6ETkMLMF5++nPQBcRObfdb/12fdNm63wUzi18vUk2kG2M2WC9X44zcfjy53wFcMgYk2uMqQZWABfh25/zOS39XNv08/bnRLEJSLVmTATjHBRbaXNMrSYignOf8T3GmGfqnVoJnJv5MB3n2MW543dasyfGAYXnurjewhgz1xiTYIxJwvk5rjHG3AasBaZYxRq2+dzPYopV3qv+0jTG5ADHRGSAdWgizr3pffZzxnnLaZyIhFn/zs+12Wc/53pa+rmuAq4Ska5WT+wq69j5sXvQxuYBo2uBfcAB4Fd2x9NGbZqAs4u5HdhmfV2L897sJ8B+67/RVnnBOfvrALAD54wS29vRivZ/B3jPet0X2AhkAW8BIdbxUOt9lnW+r91xn2dbhwMZ1mf9DtDV1z9n4HfAXmAnsAgI8bXPGXgT5xhMNc6ewYzz+VyBe6y2ZwF3tyYmfTJbKaWUS/5860kppZQbNFEopZRySROFUkoplzRRKKWUckkThVJKKZc0USillHJJE4VSSimXNFEopZRy6f8AvpUBLdUgbbwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, classes: int, smoothing: float = 0.1):\n",
    "        super().__init__()\n",
    "        assert 0 <= smoothing < 1\n",
    "        if not smoothing:\n",
    "            self.criterion_entropy = nn.CrossEntropyLoss()\n",
    "            print(\"Deactivated smoothing, apply CrossEntropyLoss.\")\n",
    "        else:\n",
    "            self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "            print(\"Activated smoothing, apply KLDivLoss.\")\n",
    "\n",
    "        self.classes = classes\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1 - smoothing\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_label_to_smooth(self, true_labels: torch.Tensor):\n",
    "        label_shape = torch.Size((true_labels.size(0), self.classes))\n",
    "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
    "        true_dist.fill_(self.smoothing / (self.classes - 1))\n",
    "        true_dist = true_dist.scatter_(1, true_labels.data, self.confidence)\n",
    "        return true_dist\n",
    "\n",
    "    def forward(\n",
    "        self, prediction: torch.Tensor, true_labels: Union[np.ndarray, torch.Tensor]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        prediction  -> shape == [batch, self.classes]\n",
    "        true_labels -> shape == [batch, 1]\n",
    "        \"\"\"\n",
    "        if prediction.shape[1] != self.classes:\n",
    "            raise ValueError(\n",
    "                f\"Mismatch between prediction and specified class number, have pre-specified classes equal to {self.classes} while {prediction.shape[1]} in prediction\"\n",
    "            )\n",
    "        if not isinstance(true_labels, torch.Tensor):\n",
    "            true_labels = torch.tensor(true_labels, dtype=torch.long)\n",
    "        else:\n",
    "            true_labels = true_labels.type(torch.long)\n",
    "        if self.smoothing:\n",
    "            print(true_labels)\n",
    "            print(\"----------\")\n",
    "            true_labels = self.convert_label_to_smooth(true_labels.reshape(-1, 1))\n",
    "            print(\"convert to smooth\")\n",
    "            print(\"----------\")\n",
    "            print(true_labels)\n",
    "            prediction = prediction.log_softmax(-1)\n",
    "            loss = self.criterion(prediction, true_labels)\n",
    "        else:\n",
    "            loss = self.criterion_entropy(prediction, true_labels.reshape(-1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated smoothing, apply KLDivLoss.\n"
     ]
    }
   ],
   "source": [
    "model = LabelSmoothing(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.randn(4, 5)\n",
    "label = torch.tensor([0, 4, 3, 1]).reshape(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [1]])\n",
      "----------\n",
      "convert to smooth\n",
      "----------\n",
      "tensor([[0.9000, 0.0250, 0.0250, 0.0250, 0.0250],\n",
      "        [0.0250, 0.0250, 0.0250, 0.0250, 0.9000],\n",
      "        [0.0250, 0.0250, 0.0250, 0.9000, 0.0250],\n",
      "        [0.0250, 0.9000, 0.0250, 0.0250, 0.0250]])\n"
     ]
    }
   ],
   "source": [
    "loss = model(prediction, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Bias Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight_decay(net, l2_value, skip_list=[]):\n",
    "    decay, no_decay = [], []\n",
    "    for name, param in net.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # skip frozen weights\n",
    "        # skip bias and bn layer\n",
    "        if name.endswith(\".bias\") or (\"_bn\" in name) or (name in skip_list):\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {\"params\": no_decay, \"weight_decay\": 0.0},\n",
    "        {\"params\": decay, \"weight_decay\": l2_value},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18()\n",
    "parameters = add_weight_decay(model, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[0][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[1][\"weight_decay\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.beta import Beta\n",
    "\n",
    "\n",
    "class Mixup(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.beta = Beta(alpha, alpha)\n",
    "\n",
    "    def __get_mixup_batch(\n",
    "        self, mini_batch_image: torch.Tensor, mini_batch_label: torch.Tensor\n",
    "    ):\n",
    "        lambda_ = self.beta.sample()\n",
    "        batch_size = mini_batch_image.shape[0]\n",
    "        shuffle = torch.randperm(batch_size)\n",
    "        shuffle_mini_batch_x = mini_batch_image[shuffle]\n",
    "        shuffle_mini_batch_y = mini_batch_label[shuffle]\n",
    "        mixup_x = mini_batch_image * lambda_ + (1 - lambda_) * shuffle_mini_batch_x\n",
    "        return (\n",
    "            mixup_x,\n",
    "            mini_batch_label.reshape(-1),\n",
    "            shuffle_mini_batch_y.reshape(-1),\n",
    "            lambda_,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        mini_batch_image: torch.Tensor,\n",
    "        mini_batch_label: torch.Tensor,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        mini_batch_image -> shape == [batch, channel, height, width]\n",
    "        mini_batch_label -> shape == [batch, 1] or [batch]\n",
    "        \"\"\"\n",
    "        (\n",
    "            mixup_x,\n",
    "            mini_batch_label,\n",
    "            shuffle_mini_batch_y,\n",
    "            lambda_,\n",
    "        ) = self.__get_mixup_batch(mini_batch_image, mini_batch_label)\n",
    "        output = model(mixup_x)\n",
    "        loss = self.criterion(output, mini_batch_label) * lambda_ + (\n",
    "            1 - lambda_\n",
    "        ) * self.criterion(output, shuffle_mini_batch_y)\n",
    "        return mixup_x, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Mixup()\n",
    "model = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_image = torch.cat((torch.ones(3, 3, 64, 64) , torch.zeros(3, 3, 64, 64)), 0)\n",
    "mini_batch_label = torch.tensor([1, 1, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_, loss = trainer(model, mini_batch_image, mini_batch_label)\n",
    "for _ in range(6):\n",
    "    plt.subplot(231+_)\n",
    "    plt.title(round((image_[_].mean()).item(), 2))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_[_].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teacher-Student Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature: Union[int, float] = 2):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.temperature = temperature\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.logsoftmax = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, student_output: torch.Tensor, teacher_output: torch.Tensor):\n",
    "        \"\"\"\n",
    "        student_output -> shape == [batch, class_number]\n",
    "        teacher_output -> shape == [batch, class_number]\n",
    "        \"\"\"\n",
    "\n",
    "        if student_output.shape != teacher_output.shape:\n",
    "            raise ValueError(\n",
    "                f\"Mismatch between student_output and teacher_output, got student_output : {student_output.shape} & teacher_output : {teacher_output.shape} respectively\"\n",
    "            )\n",
    "        student_output = self.logsoftmax(student_output / self.temperature)\n",
    "        teacher_output = self.softmax(teacher_output / self.temperature)\n",
    "\n",
    "        loss = (\n",
    "            self.criterion(student_output, teacher_output)\n",
    "            * self.temperature\n",
    "            * self.temperature\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "distill = DistillationLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_output = torch.randn(32, 4)\n",
    "teacher_output = torch.randn(32, 4)\n",
    "loss = distill(student_output, teacher_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(Conv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight = self.weight\n",
    "        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,\n",
    "                                  keepdim=True).mean(dim=3, keepdim=True)\n",
    "        weight = weight - weight_mean\n",
    "        std = weight.view(weight.size(0), -1).std(dim=1).view(-1, 1, 1, 1) + 1e-5\n",
    "        weight = weight / std.expand_as(weight)\n",
    "        return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv2d(12, 12, 3)\n",
    "output = model(torch.randn(1, 12 ,32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/GN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(16, 10, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ = dummy_input.mean([0, 2, 3], keepdim=True) #normalize 以 [0,2,3] 為主\n",
    "std_ = dummy_input.std([0, 2, 3], keepdim=True)\n",
    "normalization = (dummy_input - average_) / std_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 當N group == 1 時, GN == LN, 當 group == C 時, GN == IN\n",
    "n_group = 5\n",
    "dummy_input_copy = dummy_input.clone()\n",
    "b, c, h, w = dummy_input_copy.size()\n",
    "dummy_input_copy = dummy_input_copy.reshape(b, n_group, int(c / n_group), h, w)\n",
    "average_ = dummy_input_copy.mean([2, 3, 4], keepdim=True)\n",
    "std_ = dummy_input_copy.std([2, 3, 4], keepdim=True)\n",
    "normalization = (dummy_input_copy - average_) / std_\n",
    "normalization = normalization.reshape(b, c, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
